# Step 1: Install necessary libraries
!pip install transformers gradio

# Step 2: Import libraries
from transformers import GPT2LMHeadModel, GPT2Tokenizer
import gradio as gr

# Step 3: Load model and tokenizer
model_name = "gpt2"
tokenizer = GPT2Tokenizer.from_pretrained(model_name)
model = GPT2LMHeadModel.from_pretrained(model_name)

# Step 4: Text generation function
def generate_text(prompt, temperature, top_p, max_length):
    input_ids = tokenizer.encode(prompt, return_tensors='pt')
    output = model.generate(
        input_ids,
        max_length=int(max_length),
        temperature=temperature,
        top_p=top_p,
        do_sample=True,
        num_return_sequences=1
    )
    return tokenizer.decode(output[0], skip_special_tokens=True)

# Step 5: Gradio interface
interface = gr.Interface(
    fn=generate_text,
    inputs=[
        gr.Textbox(lines=2, placeholder="Enter a prompt...", label="Prompt"),
        gr.Slider(0.1, 1.5, value=0.7, label="Temperature"),
        gr.Slider(0.1, 1.0, value=0.9, label="Top-p (Nucleus Sampling)"),
        gr.Slider(50, 300, value=150, step=10, label="Max Length")
    ],
    outputs="text",
    title="GPT-2 Text Generator"
)

# Step 6: Launch interface
interface.launch(share=True)
